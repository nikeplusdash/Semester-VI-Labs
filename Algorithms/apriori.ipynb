{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating candidate set(l+1) from frequent set(l)\n",
    "def generate(frequent_set: list):\n",
    "    candidate_set = list()\n",
    "    for itemset_1 in frequent_set:\n",
    "        for itemset_2 in frequent_set:\n",
    "            if type(itemset_1) == str:\n",
    "                itemset_1 = [itemset_1]\n",
    "            if type(itemset_2) == str:\n",
    "                itemset_2 = [itemset_2]\n",
    "            set_1 = list(sorted(itemset_1))\n",
    "            set_2 = list(sorted(itemset_2))\n",
    "            if set_1 != set_2 and set_1[:-1] == set_2[:-1] and set_1[-1] < set_2[-1]:\n",
    "                candidate_set.append(list(sorted(set(set_1)|set(set_2))))\n",
    "    return sorted(candidate_set)\n",
    "\n",
    "# Finding subsets of size l in an itemset in candidate set(l+1) for pruning\n",
    "def findsubsets(itemset: list, size: int):\n",
    "    return [subset for subset in itertools.combinations(itemset, size)]\n",
    "\n",
    "# Removing itemsets from candidate set that are not present in frequent set\n",
    "def prune(candidate_set: list,frequent_set: list,idx: int):\n",
    "    for itemset in candidate_set:\n",
    "        subsets = findsubsets(itemset,idx - 1)\n",
    "        for subset in subsets:\n",
    "            if subset in frequent_set:\n",
    "                candidate_set.pop(subset)\n",
    "                break\n",
    "    return candidate_set\n",
    "\n",
    "# Counts support for each itemset and returns a frequent itemset\n",
    "def support_counter(candidate_set: list):\n",
    "    frequent_set = dict()\n",
    "    for itemset in candidate_set:\n",
    "        for transaction in transactions:\n",
    "            if (set(itemset)<=set(transaction)):\n",
    "                key_code = \",\".join(itemset)\n",
    "                if key_code in frequent_set:\n",
    "                    frequent_set[key_code] += 1\n",
    "                else:\n",
    "                    frequent_set[key_code] = 1\n",
    "    return frequent_set\n",
    "\n",
    "# Finds confidence and support for an association rule\n",
    "def find_conf_support(association_left: list,association_right: list):\n",
    "    frequent_set = dict()\n",
    "    itemset = list(sorted(set(association_left)|set(association_right)))\n",
    "    association_count = 0\n",
    "    total_count = 0\n",
    "    for transaction in transactions:\n",
    "        if set(itemset) <= set(transaction):\n",
    "            association_count += 1\n",
    "        if set(association_left) <= set(transaction):\n",
    "            total_count += 1\n",
    "    try:\n",
    "        confidence = association_count/total_count\n",
    "        support = association_count/len(transactions)\n",
    "    except ZeroDivisionError:\n",
    "        confidence = 0\n",
    "        support = 0\n",
    "    return {\"support\": support,\"confidence\": confidence}\n",
    "\n",
    "# Finds frequency of each itemset in candidate set and then returns the frequent itemset\n",
    "def transaction_check(candidate_set: list, support_count: int):\n",
    "    frequent_set = support_counter(candidate_set)\n",
    "    filtered_itemset = list(filter(lambda x: frequent_set[x] > support_count,frequent_set))\n",
    "    return list(map(lambda x: x.split(','),filtered_itemset))\n",
    "\n",
    "# Apriori Algorithm\n",
    "def apriori(support_count: int, supress_output : bool = False):\n",
    "    save_output = sys.stdout\n",
    "    sys.stdout = (sys.stdout,open(os.devnull, 'w', encoding='utf-8'))[supress_output]\n",
    "    candidate_sets = list()\n",
    "    frequent_sets = list()\n",
    "    idx = 2\n",
    "\n",
    "    initial_set = dict()\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            if item in initial_set:\n",
    "                initial_set[item] += 1\n",
    "            else:\n",
    "                initial_set[item] = 1\n",
    "\n",
    "    candidate_sets.append([])\n",
    "    frequent_sets.append([])\n",
    "    candidate_sets.append([item for item in initial_set.keys()])\n",
    "    filtered_set = list(filter(lambda x: initial_set[x] > support_count,initial_set))\n",
    "    frequent_sets.append([[item] for item in filtered_set])\n",
    "\n",
    "    while True:\n",
    "        candidate_sets.append(generate(frequent_sets[idx-1]))\n",
    "        candidate_sets[idx] = prune(candidate_sets[idx],frequent_sets[idx-1],idx)\n",
    "        frequent_set = transaction_check(candidate_sets[idx],support_count)\n",
    "        if len(frequent_set) != 0:\n",
    "            frequent_sets.append(frequent_set)\n",
    "        else:\n",
    "            break\n",
    "        print(\"――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\\n\")\n",
    "        print(\"Round {}:\\n\\n\\tFrequent Itemsets: {}\".format(idx,frequent_sets[idx]))\n",
    "        print(\"\\n――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\")\n",
    "        idx += 1\n",
    "    sys.stdout = save_output\n",
    "    return frequent_sets\n",
    "\n",
    "# Analyses the number of frequent itemsets and the maximal sets encountered\n",
    "def frequent_item_analysis(frequent_sets: list,support_count: int):\n",
    "    i = 0\n",
    "    initial_set = dict()\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            if item in initial_set:\n",
    "                initial_set[item] += 1\n",
    "            else:\n",
    "                initial_set[item] = 1\n",
    "    iter_list = frequent_sets[1:]\n",
    "    for frequent_set in iter_list:\n",
    "        __itemset_len = len(frequent_set)\n",
    "        __support_dict = support_counter(frequent_set)\n",
    "        if i == 0:\n",
    "            __support_dict = initial_set\n",
    "        __max_item = max(__support_dict,key=lambda x: __support_dict[x])\n",
    "        __max_count = __support_dict[__max_item]\n",
    "        print(\"{}-Itemsets({}) → ({}):{}\".format(i+1,__itemset_len,__max_item,__max_count))\n",
    "        i += 1\n",
    "    print(\"Total number of transactions: \",len(transactions))\n",
    "\n",
    "# Finds all association rules for a given itemset\n",
    "def association_rules(frequent_set: list,min_support : float = 0.0,min_confidence : float = 0.0):\n",
    "    size = len(frequent_set)\n",
    "    for __size in range(1,size):\n",
    "        subsets = findsubsets(frequent_set,__size)\n",
    "        for subset in subsets:\n",
    "            absent_subset = set(frequent_set) - set(subset)\n",
    "            stats = find_conf_support(list(subset),list(absent_subset))\n",
    "            if (stats[\"confidence\"] < min_confidence) or (stats[\"support\"] < min_support):\n",
    "                continue\n",
    "            print(\"\\033[93m{:^35} → {:^35}\\033[0m\\n\\033[91m{:^70}\\033[0m\\n\".format(','.join(subset),','.join(absent_subset),str(stats)))\n",
    "\n",
    "# Printing all possible associations for a given\n",
    "def print_all_rules(frequent_itemsets: list,min_support : float = 0.0,min_confidence : float = 0.0):\n",
    "    for idx,frequent_itemset in enumerate(frequent_itemsets):\n",
    "        for itemset in frequent_itemset:\n",
    "            association_rules(itemset,min_support,min_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item(s)</th>\n",
       "      <th>Item 1</th>\n",
       "      <th>Item 2</th>\n",
       "      <th>Item 3</th>\n",
       "      <th>Item 4</th>\n",
       "      <th>Item 5</th>\n",
       "      <th>Item 6</th>\n",
       "      <th>Item 7</th>\n",
       "      <th>Item 8</th>\n",
       "      <th>Item 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Item 23</th>\n",
       "      <th>Item 24</th>\n",
       "      <th>Item 25</th>\n",
       "      <th>Item 26</th>\n",
       "      <th>Item 27</th>\n",
       "      <th>Item 28</th>\n",
       "      <th>Item 29</th>\n",
       "      <th>Item 30</th>\n",
       "      <th>Item 31</th>\n",
       "      <th>Item 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>citrus fruit</td>\n",
       "      <td>semi-finished bread</td>\n",
       "      <td>margarine</td>\n",
       "      <td>ready soups</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>tropical fruit</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>coffee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>whole milk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>pip fruit</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>cream cheese</td>\n",
       "      <td>meat spreads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>other vegetables</td>\n",
       "      <td>whole milk</td>\n",
       "      <td>condensed milk</td>\n",
       "      <td>long life bakery product</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item(s)            Item 1               Item 2          Item 3  \\\n",
       "0        4      citrus fruit  semi-finished bread       margarine   \n",
       "1        3    tropical fruit               yogurt          coffee   \n",
       "2        1        whole milk                  NaN             NaN   \n",
       "3        4         pip fruit               yogurt    cream cheese   \n",
       "4        4  other vegetables           whole milk  condensed milk   \n",
       "\n",
       "                     Item 4 Item 5 Item 6 Item 7 Item 8 Item 9  ... Item 23  \\\n",
       "0               ready soups    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
       "1                       NaN    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
       "2                       NaN    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
       "3              meat spreads    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
       "4  long life bakery product    NaN    NaN    NaN    NaN    NaN  ...     NaN   \n",
       "\n",
       "  Item 24 Item 25 Item 26 Item 27 Item 28 Item 29 Item 30 Item 31 Item 32  \n",
       "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "4     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset from https://www.kaggle.com/irfanasrullah/groceries\n",
    "\n",
    "dataset = pd.read_csv('./groceries.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['citrus fruit', 'semi-finished bread', 'margarine', 'ready soups'],\n",
      " ['tropical fruit', 'yogurt', 'coffee'],\n",
      " ['whole milk']]\n"
     ]
    }
   ],
   "source": [
    "transactions = list()\n",
    "for row in range(len(dataset)):\n",
    "    transactions.append(list(dataset.iloc[row,1:].dropna()))\n",
    "\n",
    "pprint(transactions[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Running the Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the minimum support count threshold: 34\n",
      "Minimum Support Count:  34\n"
     ]
    }
   ],
   "source": [
    "support_count = int(input(\"Enter the minimum support count threshold: \"))\n",
    "print(\"Minimum Support Count: \", support_count)\n",
    "frequent_itemsets = apriori(support_count,supress_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent Sets with maximum frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Itemsets(130) → (whole milk):2513\n",
      "2-Itemsets(956) → (other vegetables,whole milk):736\n",
      "3-Itemsets(603) → (other vegetables,root vegetables,whole milk):228\n",
      "4-Itemsets(57) → (other vegetables,root vegetables,whole milk,yogurt):77\n",
      "5-Itemsets(1) → (other vegetables,root vegetables,tropical fruit,whole milk,yogurt):35\n",
      "Total number of transactions:  9835\n"
     ]
    }
   ],
   "source": [
    "frequent_item_analysis(frequent_itemsets,support_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Associations for a given support and confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter min support threshold: 0.02\n",
      "Enter min confidence threshold: 0.4\n",
      "\u001b[93m               beef                 →             whole milk             \u001b[0m\n",
      "\u001b[91m  {'support': 0.02125063548551093, 'confidence': 0.4050387596899225}  \u001b[0m\n",
      "\n",
      "\u001b[93m              butter                →             whole milk             \u001b[0m\n",
      "\u001b[91m  {'support': 0.02755465175394001, 'confidence': 0.4972477064220184}  \u001b[0m\n",
      "\n",
      "\u001b[93m               curd                 →             whole milk             \u001b[0m\n",
      "\u001b[91m {'support': 0.026131164209456024, 'confidence': 0.4904580152671756}  \u001b[0m\n",
      "\n",
      "\u001b[93m           domestic eggs            →             whole milk             \u001b[0m\n",
      "\u001b[91m {'support': 0.029994916115912557, 'confidence': 0.47275641025641024} \u001b[0m\n",
      "\n",
      "\u001b[93m         frozen vegetables          →             whole milk             \u001b[0m\n",
      "\u001b[91m  {'support': 0.02043721403152008, 'confidence': 0.4249471458773784}  \u001b[0m\n",
      "\n",
      "\u001b[93m             margarine              →             whole milk             \u001b[0m\n",
      "\u001b[91m {'support': 0.024199288256227757, 'confidence': 0.4131944444444444}  \u001b[0m\n",
      "\n",
      "\u001b[93m          root vegetables           →          other vegetables          \u001b[0m\n",
      "\u001b[91m {'support': 0.047381799694966954, 'confidence': 0.43470149253731344} \u001b[0m\n",
      "\n",
      "\u001b[93m        whipped/sour cream          →          other vegetables          \u001b[0m\n",
      "\u001b[91m {'support': 0.02887646161667514, 'confidence': 0.40283687943262414}  \u001b[0m\n",
      "\n",
      "\u001b[93m          root vegetables           →             whole milk             \u001b[0m\n",
      "\u001b[91m {'support': 0.048906964921199794, 'confidence': 0.44869402985074625} \u001b[0m\n",
      "\n",
      "\u001b[93m          tropical fruit            →             whole milk             \u001b[0m\n",
      "\u001b[91m {'support': 0.04229791560752415, 'confidence': 0.40310077519379844}  \u001b[0m\n",
      "\n",
      "\u001b[93m        whipped/sour cream          →             whole milk             \u001b[0m\n",
      "\u001b[91m {'support': 0.032231825114387394, 'confidence': 0.44964539007092197} \u001b[0m\n",
      "\n",
      "\u001b[93m              yogurt                →             whole milk             \u001b[0m\n",
      "\u001b[91m {'support': 0.05602440264361973, 'confidence': 0.40160349854227406}  \u001b[0m\n",
      "\n",
      "\u001b[93m other vegetables,root vegetables   →             whole milk             \u001b[0m\n",
      "\u001b[91m {'support': 0.023182511438739197, 'confidence': 0.4892703862660944}  \u001b[0m\n",
      "\n",
      "\u001b[93m    root vegetables,whole milk      →          other vegetables          \u001b[0m\n",
      "\u001b[91m {'support': 0.023182511438739197, 'confidence': 0.47401247401247404} \u001b[0m\n",
      "\n",
      "\u001b[93m      other vegetables,yogurt       →             whole milk             \u001b[0m\n",
      "\u001b[91m  {'support': 0.02226741230299949, 'confidence': 0.5128805620608899}  \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_support = float(input(\"Enter min support threshold: \"))\n",
    "min_confidence = float(input(\"Enter min confidence threshold: \"))\n",
    "print_all_rules(frequent_itemsets,min_support = min_support,min_confidence = min_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining Rules for a given itemset input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter an itemset separated by commas: whole milk, yogurt, rolls/buns\n",
      "\u001b[1mMining rules for: ['whole milk', 'yogurt', 'rolls/buns'] \u001b[0m\n",
      "\u001b[93m            whole milk              →          yogurt,rolls/buns         \u001b[0m\n",
      "\u001b[91m{'support': 0.015556685307574987, 'confidence': 0.060883406287306006} \u001b[0m\n",
      "\n",
      "\u001b[93m              yogurt                →        rolls/buns,whole milk       \u001b[0m\n",
      "\u001b[91m {'support': 0.015556685307574987, 'confidence': 0.11151603498542274} \u001b[0m\n",
      "\n",
      "\u001b[93m            rolls/buns              →          yogurt,whole milk         \u001b[0m\n",
      "\u001b[91m {'support': 0.015556685307574987, 'confidence': 0.0845771144278607}  \u001b[0m\n",
      "\n",
      "\u001b[93m         whole milk,yogurt          →             rolls/buns             \u001b[0m\n",
      "\u001b[91m {'support': 0.015556685307574987, 'confidence': 0.2776769509981851}  \u001b[0m\n",
      "\n",
      "\u001b[93m       whole milk,rolls/buns        →               yogurt               \u001b[0m\n",
      "\u001b[91m {'support': 0.015556685307574987, 'confidence': 0.2746858168761221}  \u001b[0m\n",
      "\n",
      "\u001b[93m         yogurt,rolls/buns          →             whole milk             \u001b[0m\n",
      "\u001b[91m {'support': 0.015556685307574987, 'confidence': 0.4526627218934911}  \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frequent_set = list(map(lambda x: str(x).strip(),input(\"Enter an itemset separated by commas: \").split(\",\")))\n",
    "print(\"\\033[1mMining rules for:\",frequent_set,\"\\033[0m\")\n",
    "association_rules(frequent_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['E', 'K', 'M', 'N', 'O', 'Y'],\n",
      " ['D', 'E', 'K', 'N', 'O', 'Y'],\n",
      " ['A', 'E', 'K', 'M'],\n",
      " ['L', 'K', 'M', 'U', 'Y'],\n",
      " ['L', 'E', 'I', 'K', 'O']]\n"
     ]
    }
   ],
   "source": [
    "transactions = [\n",
    " [\"E\", \"K\", \"M\", \"N\", \"O\", \"Y\"],\n",
    " [\"D\", \"E\", \"K\", \"N\", \"O\", \"Y\"],\n",
    " [\"A\", \"E\", \"K\", \"M\"],\n",
    " [\"L\", \"K\", \"M\", \"U\", \"Y\"],\n",
    " [\"L\", \"E\", \"I\", \"K\", \"O\"]\n",
    "]\n",
    "\n",
    "pprint(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the minimum support count threshold: 2\n",
      "Minimum Support Count:  2\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "\n",
      "Round 2:\n",
      "\n",
      "\tFrequent Itemsets: [['E', 'K'], ['E', 'O'], ['K', 'M'], ['K', 'O'], ['K', 'Y']]\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "\n",
      "Round 3:\n",
      "\n",
      "\tFrequent Itemsets: [['E', 'K', 'O']]\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\n"
     ]
    }
   ],
   "source": [
    "support_count = int(input(\"Enter the minimum support count threshold: \"))\n",
    "print(\"Minimum Support Count: \", support_count)\n",
    "frequent_itemsets = apriori(support_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent Sets with maximum frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Itemsets(5) → (K):5\n",
      "2-Itemsets(5) → (E,K):4\n",
      "3-Itemsets(1) → (E,K,O):3\n",
      "Total number of transactions:  5\n"
     ]
    }
   ],
   "source": [
    "frequent_item_analysis(frequent_itemsets,support_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Associations for a given support and confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter min support threshold: 0.6\n",
      "Enter min confidence threshold: 0.8\n",
      "\u001b[93m                 E                  →                  K                 \u001b[0m\n",
      "\u001b[91m                 {'support': 0.8, 'confidence': 1.0}                  \u001b[0m\n",
      "\n",
      "\u001b[93m                 K                  →                  E                 \u001b[0m\n",
      "\u001b[91m                 {'support': 0.8, 'confidence': 0.8}                  \u001b[0m\n",
      "\n",
      "\u001b[93m                 O                  →                  E                 \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 1.0}                  \u001b[0m\n",
      "\n",
      "\u001b[93m                 M                  →                  K                 \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 1.0}                  \u001b[0m\n",
      "\n",
      "\u001b[93m                 O                  →                  K                 \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 1.0}                  \u001b[0m\n",
      "\n",
      "\u001b[93m                 Y                  →                  K                 \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 1.0}                  \u001b[0m\n",
      "\n",
      "\u001b[93m                 O                  →                 E,K                \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 1.0}                  \u001b[0m\n",
      "\n",
      "\u001b[93m                E,O                 →                  K                 \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 1.0}                  \u001b[0m\n",
      "\n",
      "\u001b[93m                K,O                 →                  E                 \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 1.0}                  \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_support = float(input(\"Enter min support threshold: \"))\n",
    "min_confidence = float(input(\"Enter min confidence threshold: \"))\n",
    "print_all_rules(frequent_itemsets,min_support = min_support,min_confidence = min_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mining Rules for a given itemset input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter an itemset separated by commas: E,K,O\n",
      "\u001b[1mMining rules for: ['E', 'K', 'O'] \u001b[0m\n",
      "\u001b[93m                 E                  →                 K,O                \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 0.75}                 \u001b[0m\n",
      "\n",
      "\u001b[93m                 K                  →                 E,O                \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 0.6}                  \u001b[0m\n",
      "\n",
      "\u001b[93m                 O                  →                 E,K                \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 1.0}                  \u001b[0m\n",
      "\n",
      "\u001b[93m                E,K                 →                  O                 \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 0.75}                 \u001b[0m\n",
      "\n",
      "\u001b[93m                E,O                 →                  K                 \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 1.0}                  \u001b[0m\n",
      "\n",
      "\u001b[93m                K,O                 →                  E                 \u001b[0m\n",
      "\u001b[91m                 {'support': 0.6, 'confidence': 1.0}                  \u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frequent_set = list(map(lambda x: str(x).strip(),input(\"Enter an itemset separated by commas: \").split(\",\")))\n",
    "print(\"\\033[1mMining rules for:\",frequent_set,\"\\033[0m\")\n",
    "association_rules(frequent_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
